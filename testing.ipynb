{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Users\\91976\\Desktop\\programming\\AI and Ml\\projects\\sign language detector\\sign_detector_mobilenetV3.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(r\"C:\\Users\\91976\\Desktop\\programming\\AI and Ml\\projects\\sign language detector\\asl_dataset\\2\\hand1_2_left_seg_1_cropped.jpeg\")\n",
    "\n",
    "img = cv.resize(img,(224,224))\n",
    "im = np.array(img , dtype=np.float32)\n",
    "im = im / 255.0\n",
    "test_image = np.expand_dims(im,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'],test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference output is [[1.6562780e-03 1.2725753e-02 5.7774568e-01 7.5601102e-03 1.9421395e-03\n",
      "  5.8297563e-04 7.5267933e-02 1.1353627e-03 4.7108933e-04 5.7595238e-02\n",
      "  3.3213399e-04 4.3566339e-03 2.8223880e-03 1.6123852e-03 8.2277303e-04\n",
      "  9.5913755e-03 2.7914462e-04 3.2094389e-04 2.5601815e-03 3.1215016e-04\n",
      "  4.3286770e-03 4.7560962e-04 2.4261030e-03 1.4874899e-03 2.8933422e-03\n",
      "  2.7803381e-04 4.3650475e-04 5.4112589e-03 9.9110529e-03 4.5280205e-03\n",
      "  1.4944434e-02 1.4708515e-01 2.0879827e-02 1.0711274e-02 1.1400869e-03\n",
      "  1.3370575e-02]]\n"
     ]
    }
   ],
   "source": [
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Inference output is {}\".format(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ab03924b0a6784d01348d8b7d05bd4ac764873ded1b07aeb381424a5f34fd06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
